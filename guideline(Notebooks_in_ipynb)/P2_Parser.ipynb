{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "KG0_zbMKd4aS",
        "W1Zrnd4Hq7lU",
        "lzFEbyJasw-v",
        "vDlb_6-ms14i"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Second Project: Parsing & AST"
      ],
      "metadata": {
        "id": "3fwLj5CiRDqm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The second project requires you to implement a Parser for the MiniJava language and use it to build an abstract syntax tree (AST) as output.\n",
        "\n",
        "Like the first project, you will also\n",
        "use the [SLY](https://sly.readthedocs.io/en/latest/sly.html) library. Moreover, a series of classes representing all AST nodes will be provided.\n",
        "\n",
        "‚ùóAdvices\n",
        "\n",
        "- *Read before doing* \\\n",
        "  There are a lot of implementation details to be aware of. If you find them in your code without any context, debugging will be rather painfull.\n",
        "- *Attention to comments in code blocks* \\\n",
        "  The comments highlight the changes between code blocks.\n",
        "- *Don't skip SLY's documentation* \\\n",
        "  We'll discuss some aspects regarding SLY here, but it is by no means a replacement for the full-fledged documentation.\n",
        "- *First, semantic rules, then, semantic actions* \\\n",
        "  Don't write the semantic rules and build the AST simultaneously. First define the semantic rules and make sure they are valid. Then start building the AST by implementing the semantic actions.\n",
        "- *Test Driven Development.* \\\n",
        "The unit tests are sorted by difficulty. When building the AST, do it test by test: instantiate only the nodes necessary for the first test to pass, then move onto the second, and so on.\n",
        "\n",
        "üìö References\n",
        "\n",
        "- [BNF vs EBNF](https://condor.depaul.edu/ichu/csc447/notes/wk3/BNF.pdf) - A bit about BNF and its extended form.\n",
        "- [MiniJava EBNF grammar](https://colab.research.google.com/drive/1kOGQxBlfoauANIgHYKTuDwhrpd7peea6?usp=sharing) - The grammar you'll have to implement.\n",
        "- [SLY's parser documentation](https://sly.readthedocs.io/en/latest/sly.html#writing-a-parser) - Read it with care.\n",
        "- MiniJava AST examples - Look at the in-out test files for each test.\n"
      ],
      "metadata": {
        "id": "1v8J1VYHRaao"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Goal"
      ],
      "metadata": {
        "id": "79eDyK2qPSE1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Our goal in this project is essentially to feed a code snippet to our compiler and receive an AST as result.\n",
        "\n",
        "Say we are given three global declarations. The first is a initialized integer, second is a uninitialized integer, and the third an integer matrix:\n",
        "\n",
        "```java\n",
        "class Example1 {\n",
        "  int a = 3 * 4 + 5, c;\n",
        "  int [] b = new int[10];\n",
        "}\n",
        "```\n",
        "\n",
        "Then, we wish to represent the given code as an AST like the following:\n",
        "\n",
        "```yaml\n",
        "Program:\n",
        "    ClassDecl: ID(name=Example1) @ 1:1\n",
        "        VarDecl: ID(name=a) @ 2:5\n",
        "            Type: int @ 2:1\n",
        "            BinaryOp: + @ 2:9\n",
        "                BinaryOp: * @ 2:9\n",
        "                    Constant: int, 3 @ 2:9\n",
        "                    Constant: int, 4 @ 2:13\n",
        "                Constant: int, 5 @ 2:17\n",
        "        VarDecl: ID(name=c) @ 2:20\n",
        "            Type: int @ 2:1\n",
        "        VarDecl: ID(name=b) @ 3:8\n",
        "            Type: int[] @ 3:1\n",
        "            NewArray: @ 3:12\n",
        "                Type: int[]\n",
        "                Constant: int, 10 @ 3:20\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "9O5cXttjSi0g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parser"
      ],
      "metadata": {
        "id": "pvTzocSIW4RX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Let's take one step at a time.\n",
        "\n",
        "First, we will see how we can parse a simple variable declaration into a tree-like representation.\n",
        "\n",
        "Say we have the following input:\n",
        "\n",
        "```\n",
        "a = 3 * 4 + 5;\n",
        "```\n",
        "\n",
        "And our goal is to properly represent this computation using a tree-like notation:\n",
        "\n",
        "```\n",
        "('program', ('var_decl', 'a', ((3, '*', 4), '+', 5)))\n",
        "```"
      ],
      "metadata": {
        "id": "wfn_0232Tajs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Grammar"
      ],
      "metadata": {
        "id": "Djvn1LyWRzBs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first order of business it to define the grammar that will be able to parse our input code snippet.\n",
        "\n",
        "Take a look at the grammar below:\n",
        "\n",
        "```\n",
        "program ::= var_decl\n",
        "\n",
        "var_decl ::= ID EQUALS expr SEMI\n",
        "\n",
        "expr ::= expr PLUS expr\n",
        "       | expr TIMES expr\n",
        "       | INT_LITERAL\n",
        "```\n",
        "We can easily implement this grammar using PLY."
      ],
      "metadata": {
        "id": "XuLPbdzzUOdM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Lexer"
      ],
      "metadata": {
        "id": "q0yLpofIYKuO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we need a lexer to tokenize our input. If we have as the input:\n",
        "```\n",
        "a = 3 * 4 + 5\n",
        "```\n",
        "\n",
        " The Lexer would return the following output\n",
        "\n",
        " ```\n",
        "LexToken(ID,'a',1,0)\n",
        "LexToken(ASSIGN,'=',1,2)\n",
        "LexToken(INT_LITERAL,3,1,4)\n",
        "LexToken(TIMES,'*',1,6)\n",
        "LexToken(INT_LITERAL,4,1,8)\n",
        "LexToken(PLUS,'+',1,10)\n",
        "LexToken(INT_LITERAL,5,1,12)\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "TQHmYpEjaG5V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Semantic Rules"
      ],
      "metadata": {
        "id": "U1dmG9lPlZ7K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next step is to implement each semantic rule of our grammar using SLY's parsing tools and the lexer we've just created:\n",
        "\n",
        "\n",
        "\n",
        "```python\n",
        "\n",
        "from sly import Parser\n",
        "\n",
        "class MJParser(Parser):\n",
        "     \"\"\"I am a parser for the MiniJava language.\"\"\"\n",
        "    tokens = MJLexer.tokens\n",
        "    start = \"program\"\n",
        "\n",
        "    def __init__(self, debug=True):\n",
        "        \"\"\"I create a new MJParser.\"\"\"\n",
        "        self.debug = debug\n",
        "        self.mjlex = MJLexer(self._lexer_error)\n",
        "\n",
        "        # Keeps track of the last token given to yacc (the lookahead token)\n",
        "        self._last_yielded_token = None\n",
        "\n",
        "    def parse(self, text, debuglevel=0):\n",
        "        \"\"\"I parse a input code snippet.\"\"\"\n",
        "        self._last_yielded_token = None\n",
        "        return super().parse(self.mjlex.tokenize(text))\n",
        "\n",
        "    def _lexer_error(self, msg, line, column):\n",
        "        # use stdout to match with the output in the .out test files\n",
        "        print(\"LexerError: %s at %d:%d\" % (msg, line, column), file=sys.stdout)\n",
        "        sys.exit(1)\n",
        "\n",
        "    def _parser_error(self, msg, coord=None):\n",
        "        # use stdout to match with the output in the .out test files\n",
        "        if coord is None:\n",
        "            print(\"ParserError: %s\" % (msg), file=sys.stdout)\n",
        "        else:\n",
        "            print(\"ParserError: %s %s\" % (msg, coord), file=sys.stdout)\n",
        "        sys.exit(1)\n",
        "    \n",
        "\n",
        "    # The decorator represents the semantic rule\n",
        "    @_(\"var_decl\")\n",
        "    def program(self, p):\n",
        "        # The body is the semantic action for the given rule.\n",
        "        return ('program')\n",
        "    \n",
        "    # tokens are used in the same way as defined in the lexer\n",
        "    @_(\"ID EQUALS expr SEMI\")\n",
        "    def var_decl(self, p):\n",
        "      pass\n",
        "\n",
        "    #  When there are several possible rules for the same non-terminal,\n",
        "    # you can either separate them into different methods, or list the\n",
        "    # rules in the same method\n",
        "    @_(\n",
        "      \"expr PLUS expr\", # 1¬∫ Semantic rule to expr\n",
        "      \"expr TIMES expr\" # 2¬∫ Semantic rule to expr\n",
        "    )\n",
        "    def expr(self, p):\n",
        "      pass\n",
        "\n",
        "    @_(\"INT_LITERAL\") # 3¬∫ Semantic rule to expr\n",
        "    def expr(self, p):\n",
        "      pass\n",
        "\n",
        "\n",
        "def main():\n",
        "    # create argument parser\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"input_file\", help=\"Path to file to be parsed\", type=str)\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # get input path\n",
        "    input_file = args.input_file\n",
        "    input_path = pathlib.Path(input_file)\n",
        "\n",
        "    # check if file exists\n",
        "    if not input_path.exists():\n",
        "        print(\"ERROR: Input\", input_path, \"not found\", file=sys.stderr)\n",
        "        sys.exit(1)\n",
        "\n",
        "    parser = MJParser(debug=False)\n",
        "\n",
        "    # open file and print ast\n",
        "    with open(input_path) as f:\n",
        "        ast = parser.parse(f.read())\n",
        "        # print(parser.log.text)\n",
        "        ast.show(buf=sys.stdout, showcoord=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "YEmSslozUijI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you have written your semantic actions and semantic rules correctly, you will be able to sucessfully generate an LALR parser for our grammar.\n",
        "\n",
        "Now we should be able to parse semantically valid inputs while also raising errors for semantically **invalid** inputs:\n",
        "\n",
        "```python\n",
        "# checking for errors on invalid input\n",
        "parser.parse(\"a = ;\")\n",
        "```\n",
        "\n",
        "The output:\n",
        "```\n",
        "Error near symbol \";\"\n",
        "```\n",
        "\n",
        "When parsing an invalid input, our error funcion p_error was correctly called, and when parsing a valid input, no error was raised:\n",
        "\n",
        "```python\n",
        "# checking if valid input passes\n",
        "parser.parse(\"a = 3 * 4 + 5;\")\n",
        "```\n",
        "\n",
        "So far, so good."
      ],
      "metadata": {
        "id": "Er-v9D6gp0EP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Semantic Actions"
      ],
      "metadata": {
        "id": "Yy8wf3pzrHb7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although we can correctly parse the code, It's of no use if there is no output from it.\n",
        "\n",
        "Our next step then is to add semantic *actions* for each of the semantic *rules* in our parser so that it may return something useful to us.\n",
        "\n",
        "A *semantic action* is essentially the action to be made once a semantic rule is identified/reduced.\n",
        "\n",
        "In SLY's case, the semantic action for each rule is defined in the function's body.\n",
        "\n",
        "Let's create a simple abstract sintax tree of our input code using semantic actions:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```python\n",
        "from sly import Parser\n",
        "\n",
        "class MJParser(Parser):\n",
        "     \"\"\"I am a parser for the MiniJava language.\"\"\"\n",
        "    tokens = MJLexer.tokens\n",
        "    start = \"program\"\n",
        "\n",
        "    # Parser functions\n",
        "    ...\n",
        "\n",
        "    # Solve ambiguity\n",
        "    precedence = ()\n",
        "\n",
        "    # The decorator represents the semantic rule\n",
        "    @_(\"var_decl\")\n",
        "    def program(self, p):\n",
        "        # The body is the semantic action for the given rule.\n",
        "        # Once an 'program' production is identified,\n",
        "        # SLY will execute this function's body as the semantic action.\n",
        "        return ('program', p.var_decl)\n",
        "\n",
        "    # Lexer tokens are used in the semantic rule\n",
        "    @_(\"ID EQUALS expr SEMI\")\n",
        "    def var_decl(self, p):\n",
        "      # Once an 'var_decl' production is identified, SLY will execute\n",
        "      # this function's body as the semantic action.\n",
        "      return ('var_decl', p.ID, p.expr)          \n",
        "\n",
        "    #  When there are several possible rules for the same non-terminal you can either separate them into different methods, or list the rules in the same method\n",
        "    @_(\n",
        "      \"expr PLUS expr\", # 1¬∫ Semantic rule to expr\n",
        "      \"expr TIMES expr\" # 2¬∫ Semantic rule to expr\n",
        "    )\n",
        "    def expr(self, p):\n",
        "      # Some functions, like this one, may handle multiple production rules.\n",
        "      # This is useful if different rules should trigger the same semantic\n",
        "      # action. In this case, regardless of the operator, we wish to generate\n",
        "      # the same tuple, so the same semantic action is used.\n",
        "      # Each element in the production is a attribute in p\n",
        "      # expr    PLUS    expr\n",
        "      # p[0]    p[1]    p[2]\n",
        "      return (p[0], p[1], p[2])\n",
        "\n",
        "    @_(\"INT_LITERAL\") # 3¬∫ Semantic rule to expr\n",
        "    def expr(self, p):\n",
        "      return (p.INT_LITERAL)    \n",
        "\n",
        "\n",
        "...\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZyoPq2BMUUsT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, whenever a semantic rule is reduced in our parser, it will return whatever value the semantic action returns in the function.\n",
        "\n",
        "Suppose the semantic action returns the following tuple T from the expression E:\n",
        "\n",
        "```python\n",
        "E: \"a = 3 * 4 + 5;\"\n",
        "T: ('program', ('var_decl', 'a', (3, '*', (4, '+', 5))))\n",
        "```\n",
        "\n",
        "The tuple T is a very simple abstract tree.\n",
        "\n",
        "This tree is wrong though: the sum operation preceeds the multiplication.\n",
        "This would return `3 * (4 + 5)` instead of `(3 * 4) + 5`.\n",
        "\n",
        "*Why* is it doing this you ask? Because we ignored the `shift/reduce` conflicts."
      ],
      "metadata": {
        "id": "QODT-4JcsafQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Shift/Reduce Conflicts"
      ],
      "metadata": {
        "id": "GMN6w1PgwOh2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚≠ê *Tip: see parser.debug file to better visualize this*\n",
        "\n",
        "Shift/reduce conflicts essentially mean the grammar is ambiguos. In other words, there is more than one valid AST for the same code.\n",
        "\n",
        "Let's dissect the cause of the conflict.\n",
        "\n",
        "Once the parser reaches the `+` token, it encounters the following situation:\n",
        "\n",
        "```\n",
        "ID EQUALS expression TIMES expression . PLUS\n",
        "```\n",
        "\n",
        "The `.` indicates the top of our parser's stack and the `PLUS` token is the lookahead token. The parser has two options here:\n",
        "\n",
        "- Shift the `PLUS` token into the stack.\n",
        "```\n",
        "ID EQUALS expression TIMES expression PLUS .\n",
        "```\n",
        "- Reduce the top of the stack using the semantic rule `expression ::= expression TIMES expression`.\n",
        "```\n",
        "ID EQUALS expression . PLUS\n",
        "```\n",
        "\n",
        "If you run a parser with this conflicts you will see this message:\n",
        "\n",
        ">  WARNING: 4 shift/reduce conflicts\n",
        "\n",
        "‚ùó**Important**: This message does not appear in pytest, only when running the tests individually and only after the first time running a new grammar. To check if your grammar is free of conflicts, we advise you to check the end of the parser.debug file that has the list of conflicts. The parser.debug file will be generated automatically after the template runtime errors are resolved. In addition, if there is more than 1 shift/reduce conflict or any reduce/reduce conflict, 3 points will be deducted from the total lab grade.\n",
        "\n",
        "The parser is not sure if it should shift the lookahead or reduce the top of the stack.\n",
        "\n",
        "It also says there are 4 conflicts. This is because the same conflict happens in 4 different scenarios:\n",
        "\n",
        "```\n",
        "ID EQUALS expression TIMES expression . PLUS\n",
        "ID EQUALS expression PLUS expression . TIMES\n",
        "ID EQUALS expression TIMES expression . TIMES\n",
        "ID EQUALS expression PLUS expression . PLUS\n",
        "```\n",
        "\n",
        "So, why did the parser not crash when it found this conflicts?\n",
        "\n",
        "Well, not all shift/reduce conflicts are bad as long as we know how to resolve them.\n",
        "\n",
        "However, SLY always resolves shift/reduce conflicts by shifting instead of reducing.\n",
        "\n",
        "In this case, shifting is the wrong action, because it causes `(4, '+', 5)` to be generated before `(3, '*', 4)`.\n",
        "\n",
        "To fix this, we must explicitly tell SLY how to resolve these conflicts."
      ],
      "metadata": {
        "id": "K71sNrktPCfJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Operator Precedence"
      ],
      "metadata": {
        "id": "suxSFEIixzne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚≠ê *Tip: there are some good examples of this in SLY's doc*\n",
        "\n",
        "SLY allows use to easily resolve these common shift/reduce conflicts between operators by using a special `precedence` variable.\n",
        "\n",
        "Let's see how we can use the `precedence` variable to force SLY to prioritize `TIMES` tokens over `PLUS` tokens:\n",
        "\n",
        "\n",
        "\n",
        "```python\n",
        "from sly import Parser\n",
        "\n",
        "\n",
        "class MJParser(Parser):\n",
        "    tokens = MJLexer.tokens\n",
        "    start = \"program\"\n",
        "\n",
        "    # Parser functions\n",
        "    ...\n",
        "\n",
        "    # Solve ambiguity\n",
        "    precedence = (\n",
        "      ('left', 'PLUS'),\n",
        "      ('left', 'TIMES'),\n",
        "    )\n",
        "\n",
        "\n",
        "    # Parser rules\n",
        "    ....\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "DIdQg2RcUtyo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After generating the new parser, there is already an indication of success: the shift/reduce warnings are gone.\n",
        "\n",
        "The simple abstract tree produced is:\n",
        "\n",
        "\n",
        "```python\n",
        "('program', ('var_decl', 'a', ((3, '*', 4), '+', 5)))\n",
        "```\n",
        "\n",
        "Another very basic syntax tree. But a correct one this time."
      ],
      "metadata": {
        "id": "Tg2GaCWYys7W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Position Tracking"
      ],
      "metadata": {
        "id": "DfVV7mF6MBNZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A last desirable feature for our parser is to track positions.\n",
        "\n",
        "By tracking positions, we are able to know which part of the code generate which tree element.\n",
        "\n",
        "To track this positions we'll use special `Cood` class and a helper function `_token_cood`:\n",
        "\n",
        "\n",
        "\n",
        "```python\n",
        "from sly import Parser\n",
        "\n",
        "class Coord:\n",
        "    \"\"\"Coordinates of a syntactic element. Consists of:\n",
        "    - Line number\n",
        "    - (optional) column number, for the Lexer\n",
        "    \"\"\"\n",
        "\n",
        "    __slots__ = (\"line\", \"column\")\n",
        "\n",
        "    def __init__(self, line, column=None):\n",
        "        self.line = line\n",
        "        self.column = column\n",
        "\n",
        "    def __str__(self):\n",
        "        if self.line and self.column is not None:\n",
        "            coord_str = \"@ %s:%s\" % (self.line, self.column)\n",
        "        elif self.line:\n",
        "            coord_str = \"@ %s\" % (self.line)\n",
        "        else:\n",
        "            coord_str = \"\"\n",
        "        return coord_str\n",
        "\n",
        "class MJParser(Parser):\n",
        "    tokens = MJLexer.tokens\n",
        "    start = \"program\"\n",
        "\n",
        "    # Other Parser functions\n",
        "    ...\n",
        "\n",
        "\n",
        "    def _token_coord(self, p):\n",
        "        last_cr = self.mjlex.text.rfind(\"\\n\", 0, p.index)\n",
        "        if last_cr < 0:\n",
        "            last_cr = -1\n",
        "        column = p.index - (last_cr)\n",
        "        return Coord(p.lineno, column)\n",
        "    \n",
        "    # Semantic actions and rules\n",
        "    ...\n",
        "\n",
        "    @_(\"ID EQUALS expr SEMI\")\n",
        "    def var_decl(self, p):\n",
        "      return ('var_decl', p.ID, p.expr, str(self._token_coord(p)))          \n",
        "\n",
        "    @_(\n",
        "      \"expr PLUS expr\", # 1¬∫ Semantic rule to expr\n",
        "      \"expr TIMES expr\" # 2¬∫ Semantic rule to expr\n",
        "    )\n",
        "    def expr(self, p):\n",
        "      return (p[0], p[1], p[2], str(self._token_coord(p)))\n",
        "\n",
        "    @_(\"INT_LITERAL\") # 3¬∫ Semantic rule to expr\n",
        "    def expr(self, p):\n",
        "      return (p.INT_LITERAL, str(self._token_coord(p)))   \n",
        "\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "J2mL-E_NMBNe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The positions are in our tree now:\n",
        "\n",
        "```python\n",
        "E: \"a = 3 * 4 + 5;\"\n",
        "\n",
        "# position format: @ line:column\n",
        "T:  ('program',\n",
        "    ('assignment',\n",
        "      'a',\n",
        "        ((3, '*', 4, '@ 1:7'), '+', 5, '@ 1:11'),\n",
        "      '@ 1:1'))\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "DTrnjFgkMBNf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neat. Now its a basic syntax tree with coordinates.\n",
        "\n",
        "With this info we know, for example, that the operation `(3, '*', 4, '1:7')` came from line 1 and column 7 of our code."
      ],
      "metadata": {
        "id": "iJl6yWXGMBNf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### EBNF to BNF"
      ],
      "metadata": {
        "id": "Xx69WYjmRlxm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üõë **SLY does not support EBNF, only BNF.**\n",
        "\n",
        "That is a bit of a catch that we haven't discussed yet.\n",
        "\n",
        "What this means is the kleene start, kleene cross, and question mark operators will not work with SLY grammar rules.\n",
        "\n",
        "So any rule in the grammar that uses the `+`, `*`, or `?` operators must be converted to BNF first.\n",
        "\n",
        "Take a look below to se how EBNF rules may be converted to BNF.\n",
        "\n",
        "EBNF:\n",
        "\n",
        "```\n",
        "animal ::= dog+\n",
        "         | cat*\n",
        "         | mouse?\n",
        "```\n",
        "\n",
        "BNF:\n",
        "\n",
        "```\n",
        "animal ::= dog_kcross\n",
        "         | cat_kstar\n",
        "         | mouse_opt\n",
        "\n",
        "dog_kcross ::= dog_kcross dog\n",
        "             | dog\n",
        "\n",
        "cat_kstar ::= cat_kstar cat\n",
        "             | empty\n",
        "\n",
        "mouse_opt ::= mouse\n",
        "            | empty\n",
        "\n",
        "empty ::=\n",
        "```\n",
        "\n",
        "So, for the previous example, we write the SLY function as:\n",
        "\n",
        "\n",
        "\n",
        "```python\n",
        "    @_(\"dog_kcross\", \"cat_kstar\", \"mouse_opt\")\n",
        "    def animal(self, p): # The production is the function name\n",
        "      # Semantic action here\n",
        "      pass\n",
        "\n",
        "    @_(\"dog_kcross dog\", \"dog_kcross\")\n",
        "    def dog_kcross(self, p):\n",
        "      pass\n",
        "\n",
        "    @_(\"cat_kstar cat\", \"empty\")\n",
        "    def cat_kstar(self, p):\n",
        "      pass\n",
        "\n",
        "    @_(\"mouse\", \"empty\")\n",
        "    def mouse_opt(self, p):\n",
        "      pass\n",
        "    \n",
        "    @_(\"\")\n",
        "    def empty(self, p):\n",
        "      pass\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "You'll need to manually apply these conversions to use the [MiniJava grammar](https://colab.research.google.com/drive/1kOGQxBlfoauANIgHYKTuDwhrpd7peea6?usp=sharing) in SLY."
      ],
      "metadata": {
        "id": "Cd_TY3ldQCOz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Upgrading to MiniJava Grammar"
      ],
      "metadata": {
        "id": "U6YZH1esPbmY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The simplified example was useful to explain the parsing basics.\n",
        "\n",
        "Now let's go back to our main goal:\n",
        "\n",
        "```java\n",
        "class Example1 {\n",
        "  int a = 3 * 4 + 5, c;\n",
        "  int[] b = new int[10];\n",
        "}\n",
        "```\n",
        "\n",
        "The old grammar is not enough to parse this. It has no concept of arrays nor typed declarations.\n",
        "\n",
        "Let's increment the grammar by simplifying some of the [MiniJava grammar rules](https://colab.research.google.com/drive/1kOGQxBlfoauANIgHYKTuDwhrpd7peea6?usp=sharing):\n",
        "\n",
        "```ebnf\n",
        "<program> ::= {<class_declaration>}+\n",
        "\n",
        "<class_declaration> ::= \"class\" <identifier> \"{\" {<compound_declaration>}* \"}\"\n",
        "\n",
        "<compound_declaration> ::= <type_specifier> <init_declarator_list> \";\"\n",
        "\n",
        "<init_declarator_list> ::= <init_declarator>\n",
        "                         | <init_declarator_list> \",\" <init_declarator>\n",
        "\n",
        "<init_declarator> ::= <identifier>\n",
        "                    | <identifier> \"=\" <assignment_expression>\n",
        "\n",
        "<type_specifier> ::= \"int\"\n",
        "                   | \"int\" \"[\" \"]\"\n",
        "\n",
        "\n",
        "<assignment_expression> ::= <binary_expression>\n",
        "                          | \"new\" \"int\" \"[\" <INT_LITERAL> \"]\"\n",
        "\n",
        "<binary_expression> ::= <INT_LITERAL>\n",
        "                      | <binary_expression> \"*\" <binary_expression>\n",
        "                      | <binary_expression> \"+\" <binary_expression>\n",
        "```\n",
        "\n",
        "Next step: update our lexer and parser with the new grammar."
      ],
      "metadata": {
        "id": "aLawNJfY6kcd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Shift/Reduce Conflict for ID"
      ],
      "metadata": {
        "id": "VxtgwIlGB5PD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Semantic Rules section shows how to create lists that accept zero or more elements (in the example, the list is called cat_kstar). In other words, rules that are followed by * in the grammar. However, in the grammar rule `{<statement>}*` that is inside `<compound_statement>`, creating the list as shown results in a shift/reduce conflict.\n",
        "\n",
        "Note that the compound statement rule allows two consecutive lists * (kstar lists):\n",
        "```\n",
        "<compound_statement> ::= \"{\" {<compound_declaration>}* {<statement>}* \"}\"\n",
        "```\n",
        "\n",
        "If you follow the rules in the first kstar list of the compound declaration, you can see that it can expect an identifier as the first rule:\n",
        "\n",
        "```\n",
        "<compound_declaration> ::= <type_specifier> <init_declarator_list> \";\"\n",
        "\n",
        "\n",
        "<type_specifier> ::= <identifier>\n",
        "                   | ...\n",
        "```\n",
        "The other rules are omitted using \"...\" since they are not important for analysis.\n",
        "\n",
        "\n",
        "On the other hand, if you follow the rules in the second kstar list of the statement, you can see that it can **also** expect an identifier as the first rule:\n",
        "```\n",
        "<statement> ::= <expresssion_statement>\n",
        "              | ...\n",
        "                 \n",
        "<expression_statement> ::= <expression> \";\"\n",
        "\n",
        "<expression> ::= <assignment_expression>\n",
        "               | ...\n",
        "               \n",
        "<assignment_expression> ::= <unary_expression> \"=\" <assignment_expression>\n",
        "                          | ...\n",
        "                          \n",
        "<unary_expression> ::= <postfix_expression>\n",
        "                     | ...\n",
        "                     \n",
        "<postfix_expression> ::= <primary_expression>\n",
        "                       | ...\n",
        "\n",
        "<primary_expression> ::= <identifier>\n",
        "                       | ...\n",
        "```\n",
        "\n",
        "Because both rules start with identifier there is a shift /reduce conflict, and, since the parser resolves using shift, the statement starts to be interpreted as a compound declaration resulting in an error in the parser in the tests that cover this case.\n",
        "\n",
        "To resolve this conflict, simply change the statement rule to one of these two options:\n",
        "\n",
        "1. Split the kstar rule into two, making a rule that accepts empty and kcross (lists with +):\n",
        "\n",
        "\n",
        "```python\n",
        "    @_(\"statement_kcross\", \"empty\")\n",
        "    def statement_kstar(self, p):\n",
        "        pass\n",
        "    @_(\"statement_kcross statement\", \"statement\")\n",
        "    def statement_kcross(self, p):\n",
        "        pass\n",
        "```\n",
        "\n",
        "2.   Use recursion on the right side:\n",
        "```python\n",
        "    @_(\"statement statement_kstar\", \"empty\")\n",
        "    def statement_kstar(self, p):\n",
        "        pass\n",
        "```"
      ],
      "metadata": {
        "id": "SjJTkCdsB9-1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Abstract Syntax Tree"
      ],
      "metadata": {
        "id": "24FR6e3G3FlO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Abstract syntax trees are data structures that better represent the structure of the program code than the parse tree. An AST can be edited and enhanced with information such as properties and annotations for each element it contains."
      ],
      "metadata": {
        "id": "bKJm9SZBdsWB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've shown how to use SLY to parse a grammar and generate a tree-like structure from it.\n",
        "\n",
        "Tuples, however, are a bit limited. Let's upgrade our AST to classes.\n",
        "\n",
        "Each node in our tree will be represented by a class. **Keep in mind that these classes will be given to you.**\n",
        "\n",
        "Your job is to use the parser to connect these classes/nodes using the SLY parser to effectively buid the AST.\n"
      ],
      "metadata": {
        "id": "9-L6ASzgdmrq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building Declarations"
      ],
      "metadata": {
        "id": "OvhMHigudstd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our goal here is to leverage the parse tree to build the AST.\n",
        "\n",
        "Whenever a reduction occurs in the parser, a semantic action is executed.\n",
        "\n",
        "With this knowledge we can return nodes that represent the reduction in question instead of simple tuples.\n",
        "\n",
        "\n",
        "Let's build the AST for the code below:\n",
        "\n",
        "```java\n",
        "class Example1 {\n",
        "  int[] b = new int[10];\n",
        "}\n",
        "```\n",
        "\n",
        "Which should look like:\n",
        "\n",
        "```yaml\n",
        "Program:\n",
        "    ClassDecl: ID(name=Example1) @ 1:1\n",
        "        VarDecl: ID(name=b) @ 3:8\n",
        "            Type: int[] @ 3:1\n",
        "            NewArray: @ 3:12\n",
        "                Type: int[]\n",
        "                Constant: int, 10 @ 3:20\n",
        "```\n",
        "\n",
        "There are 7 explicit nodes in the AST above: `Program`, `ClassDecl`, `VarDecl`, `Type`, `NewArray`, `ID`, and `Constant`.\n",
        "\n",
        "Also, some of these nodes inherit from special helper classes.\n",
        "\n",
        "Before continuing, we must defined these nodes and its helpers."
      ],
      "metadata": {
        "id": "tXDWvEJ50JuZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helpers"
      ],
      "metadata": {
        "id": "NZzW-aID4tBv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is a list of the helper methods/classes:\n",
        "\n",
        "* `class Node` - Every nodes inherts this class. It holds some base functionality for all nodes.\n",
        "* `def represent_node` - Used to dump each node as a string.\n",
        "\n",
        "These helpers don't deserve much atention since you won't be using then directly.\n",
        "\n",
        "Let's just move on."
      ],
      "metadata": {
        "id": "0-_GV8Ow4yQ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AST Nodes"
      ],
      "metadata": {
        "id": "B7LKII-V1ZCH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the helpers defined, we can proceed to define the AST nodes.\n",
        "\n",
        "We must defined `Program`, `ClassDecl`, `VarDecl`, `Type`, `NewArray`, `ID`, and `Constant` nodes:\n",
        "\n",
        "\n",
        "```python\n",
        "class Program(Node):\n",
        "    \"\"\"Node that represent the MiniJava Program\"\"\"\n",
        "\n",
        "    attr_names = ()\n",
        "\n",
        "    def __init__(self, class_decls: list[ClassDecl], coord: Coord = None):\n",
        "        \"\"\"\n",
        "        :param class_decls: program's class declarations.\n",
        "        :param coord: code position.\n",
        "        \"\"\"\n",
        "        self.class_decls = class_decls\n",
        "        self.coord = coord\n",
        "\n",
        "    def children(self):\n",
        "        return tuple(\n",
        "            (\n",
        "                (f\"class_decls[{idx}]\", class_decl)\n",
        "                for idx, class_decl in enumerate(self.class_decls or [])\n",
        "            )\n",
        "        )\n",
        "\n",
        "class ClassDecl(Node):\n",
        "    \"\"\"Node representing a Class Declaration\"\"\"\n",
        "\n",
        "    attr_names = (\"name\",)\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        name: ID,\n",
        "        extends: ID,\n",
        "        var_decls: list[VarDecl],\n",
        "        method_decls: list[MethodDecl],\n",
        "        coord: Coord = None,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        :param name: Class name.\n",
        "        :param extends: Name of the extended class.\n",
        "        :param var_decls: List of var declarations.\n",
        "        :param method_decls: List of method declarations.\n",
        "        \"\"\"\n",
        "        self.name = name\n",
        "        self.extends = extends\n",
        "        self.var_decls = var_decls\n",
        "        self.method_decls = method_decls\n",
        "        self.coord = coord\n",
        "\n",
        "    def children(self):\n",
        "        decls = (\n",
        "            ([self.extends] if self.extends is not None else [])\n",
        "            + self.var_decls\n",
        "            + self.method_decls\n",
        "        )\n",
        "        return tuple(((f\"decls[{idx}]\", decl) for idx, decl in enumerate(decls or [])))\n",
        "\n",
        "class VarDecl(Node):\n",
        "    \"\"\"Node that represents a variable declaration\"\"\"\n",
        "\n",
        "    attr_names = (\"name\",)\n",
        "\n",
        "    def __init__(self, type: Type, name: ID, init, coord: Coord = None):\n",
        "        \"\"\"\n",
        "        :param type: variable primitive type.\n",
        "        :param name: variable name.\n",
        "        :param init: initialization value.\n",
        "        :param coord: code position.\n",
        "        \"\"\"\n",
        "        self.type = type\n",
        "        self.name = name\n",
        "        self.init = init\n",
        "        self.coord = coord\n",
        "\n",
        "    def children(self):\n",
        "        nodelist = []\n",
        "        if self.type is not None:\n",
        "            nodelist.append((\"type\", self.type))\n",
        "        if self.init is not None:\n",
        "            nodelist.append((\"init\", self.init))\n",
        "        return tuple(nodelist)\n",
        "\n",
        "class Type(Node):\n",
        "    \"\"\"Node representing a type specifier\"\"\"\n",
        "\n",
        "    attr_names = (\"name\",)\n",
        "\n",
        "    def __init__(self, name: str, coord: Coord = None):\n",
        "        \"\"\"\n",
        "        :param name: type name (int, char, ...).\n",
        "        :param coord: code position.\n",
        "        \"\"\"\n",
        "        self.name = name\n",
        "        self.coord = coord\n",
        "\n",
        "    def children(self):\n",
        "        return ()\n",
        "\n",
        "class NewArray(Expr):\n",
        "    \"\"\"Expression representing a New Array allocation.\"\"\"\n",
        "\n",
        "    attr_names = ()\n",
        "\n",
        "    def __init__(self, type: Type, size: Expr, coord: Coord = None):\n",
        "        \"\"\"\n",
        "        :param type: Array type (char[] or int[]).\n",
        "        :param size: Array size.\n",
        "        :param coord: code position.\n",
        "        \"\"\"\n",
        "        self.type = type\n",
        "        self.size = size\n",
        "        self.coord = coord\n",
        "\n",
        "    def children(self):\n",
        "        nodelist = []\n",
        "        if self.type is not None:\n",
        "            nodelist.append((\"type\", self.type))\n",
        "        if self.size is not None:\n",
        "            nodelist.append((\"size\", self.size))\n",
        "        return tuple(nodelist)\n",
        "\n",
        "class ID(Node):\n",
        "    \"\"\"Node representing an identifier\"\"\"\n",
        "\n",
        "    attr_names = (\"name\",)\n",
        "\n",
        "    def __init__(self, name: str, coord: Coord = None):\n",
        "        \"\"\"\n",
        "        :param name: ID unique name.\n",
        "        :param coord: code position.\n",
        "        \"\"\"\n",
        "        self.name = name\n",
        "        self.coord = coord\n",
        "\n",
        "    def children(self):\n",
        "        return ()\n",
        "\n",
        "class Constant(Expr):\n",
        "    \"Node representing a constant\"\n",
        "\n",
        "    attr_names = (\"type\", \"value\")\n",
        "\n",
        "    def __init__(self, type: str, value, coord: Coord = None):\n",
        "        \"\"\"\n",
        "        :param type: constant type.\n",
        "        :param value: constant value.\n",
        "        :param coord: code position.\n",
        "        \"\"\"\n",
        "        self.type = type\n",
        "        self.value = value\n",
        "        self.coord = coord\n",
        "\n",
        "    def children(self):\n",
        "        return ()\n",
        "```\n"
      ],
      "metadata": {
        "id": "R_nbnMfH1bdQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each node has a set of attributes that represent one of two things:\n",
        "\n",
        "- A intrinsic property of the node (like code position).\n",
        "- Child nodes (like the list of `ClassDecl` in the `Program` node)\n",
        "\n",
        "Each node also has a `attr_names` class attribute. This is used to print the nodes.\n",
        "\n",
        "**Just a reminder that these nodes are already defined in the project's template.**"
      ],
      "metadata": {
        "id": "VGIVncIE6Rg9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MiniJava Declarations"
      ],
      "metadata": {
        "id": "8XN5K0jMlPDl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A MiniJava type consists of a basic type declaration or a char/int array type.\n",
        "\n",
        "In `int[] b`, for example is a int array. When initialized with `new int[10]` it produces a `NewArray` node in the AST.\n",
        "\n",
        "In our AST, `VarDecl` represents the basic var declaration, `ClassDecl` the class declaration, `MethodDecl` a method declaration and `MainMethodDecl` is the method declaration of MiniJava main method.\n",
        "\n",
        "> Note that in the MiniJava grammar var declarations must be written before any other rules in the method body.\n",
        "\n",
        "```java\n",
        "/*\n",
        "Valid code in MiniJava, var is declared\n",
        "before the print statement.\n",
        "*/\n",
        "class Example1 {\n",
        "  public static void main(String[] args) {\n",
        "    int var = 2;\n",
        "    print(\"Hello\");\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "/*\n",
        "Invalid code in MiniJava, var is declared\n",
        "after the print statement.\n",
        "The compiler must emit a parser error.\n",
        "*/\n",
        "class Example2 {\n",
        "  public static void main(String[] args) {\n",
        "    print(\"Hello\");\n",
        "    int var = 2;\n",
        "  }\n",
        "}\n",
        "\n",
        "/*\n",
        "Valid code in MiniJava, var is declared\n",
        "before the print statement.\n",
        "In MiniJava, a value can be assigned to\n",
        "a variable after its declaration.\n",
        "*/\n",
        "class Example3 {\n",
        "  public static void main(String[] args) {\n",
        "    int var;\n",
        "    print(\"Hello\");\n",
        "    var = 2;\n",
        "  }\n",
        "}\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "B36gxkZ-lv4A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building the AST"
      ],
      "metadata": {
        "id": "gzG6gwOc6-Gy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we know how declarations are parsed and structured with AST nodes.\n",
        "\n",
        "Next step is to join these two informations in order to build the AST.\n",
        "\n",
        "Let's try to buit the ast for the input code:\n",
        "\n",
        "```java\n",
        "class Example1 {\n",
        "  int[] b = new int[10];\n",
        "}\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```python\n",
        "from sly import Parser\n",
        "\n",
        "\n",
        "class MJParser(Parser):\n",
        "    tokens = MJLexer.tokens\n",
        "    start = \"program\"\n",
        "\n",
        "    # Parser functions\n",
        "    ...\n",
        "\n",
        "    # Solve ambiguity\n",
        "    precedence = (\n",
        "      ('left', 'PLUS'),\n",
        "      ('left', 'TIMES'),\n",
        "    )\n",
        "\n",
        "    @_(\"class_declaration_list\")\n",
        "    def program(self, p):\n",
        "        # The root node of AST\n",
        "        return Program(class_decls=p.class_declaration_list, coord=None)\n",
        "\n",
        "    # Class declaration list must return a python list\n",
        "    @_(\"class_declaration\")\n",
        "    def class_declaration_list(self, p):\n",
        "        return [p.class_declaration]\n",
        "\n",
        "    @_(\"class_declaration_list class_declaration\")\n",
        "    def class_declaration_list(self, p):\n",
        "        p.class_declaration_list.append(p.class_declaration)\n",
        "        return p.class_declaration_list\n",
        "\n",
        "\n",
        "    @_(\n",
        "        \"CLASS identifier LBRACE compound_declarations RBRACE\"\n",
        "    )\n",
        "    def class_declaration(self, p):\n",
        "        return ClassDecl(\n",
        "            name=p.identifier,\n",
        "            var_decls=p.compound_declarations,\n",
        "            coord=self._token_coord(p),\n",
        "        )\n",
        "    \n",
        "    @_(\"empty\")\n",
        "    def compound_declarations(self, p):\n",
        "        return []\n",
        "\n",
        "    @_(\"compound_declarations compound_declaration\")\n",
        "    def compound_declarations(self, p):\n",
        "        compound_declarations = p.compound_declarations + p.compound_declaration\n",
        "        return compound_declarations\n",
        "\n",
        "    @_(\"type_specifier init_declarator_list SEMI\")\n",
        "    def compound_declaration(self, p):\n",
        "        for var_decl in p.init_declarator_list:\n",
        "            var_decl.type = p.type_specifier\n",
        "        return p.init_declarator_list\n",
        "\n",
        "    @_(\"init_declarator\")\n",
        "    def init_declarator_list(self, p):\n",
        "        return [p.init_declarator]\n",
        "\n",
        "    @_(\"init_declarator_list COMMA init_declarator\")\n",
        "    def init_declarator_list(self, p):\n",
        "        p.init_declarator_list.append(p.init_declarator)\n",
        "        return p.init_declarator_list\n",
        "\n",
        "    @_(\"identifier\")\n",
        "    def init_declarator(self, p):\n",
        "        return p[0]\n",
        "\n",
        "    @_(\"<identifier> ASSIGN <assignment_expression>\")\n",
        "    def init_declarator(self, p):\n",
        "        return VarDecl(\n",
        "            type=None, name=p.identifier, init=p.assignment_expression, coord=self._token_coord(p)\n",
        "        )\n",
        "    \n",
        "    @_(\"ID\")\n",
        "    def identifier(self, p):\n",
        "      return ID(name=p.ID, coord=self._token_coord(p))\n",
        "\n",
        "    @_(\"INT\")\n",
        "    def type_specifier(self, p):\n",
        "        return Type(name=p[0], coord=self._token_coord(p))\n",
        "\n",
        "    @_(\"INT LBRACKET RBRACKET\")\n",
        "    def type_specifier(self, p):\n",
        "        return Type(name=\"int[]\", coord=self._token_coord(p))\n",
        "    \n",
        "    @_(\"binary_expression\")\n",
        "    def assignment_expression(self, p):\n",
        "        return p.assignment_expression\n",
        "\n",
        "    @_(\"NEW INT LBRACKET INT_LITERAL RBRACKET\")\n",
        "    def assignment_expression(self, p):\n",
        "        arr_size = Constant(type=\"int\", value=p.INT_LITERAL, coord=self._token_coord(p))\n",
        "        return NewArray(type=\"int\", size=arr_size, coord=self._token_coord(p))\n",
        "\n",
        "    @_(\"INT_LITERAL\")\n",
        "    def binary_expression(self, p):\n",
        "        return Constant(type=\"int\", value=p.INT_LITERAL, coord=self._token_coord(p))\n",
        "\n",
        "    @_(\n",
        "        \"binary_expression TIMES binary_expression\",\n",
        "        \"binary_expression PLUS binary_expression\",\n",
        "    )\n",
        "    def binary_expression(self, p):\n",
        "        return BinaryOp(op=p[1], left=p[0], right=p[2], coord=self._token_coord(p))\n",
        "    \n",
        "    @_(\"\")\n",
        "    def empty(self, p):\n",
        "        return None\n",
        "\n",
        "     \n",
        "```\n",
        "\n",
        "The AST result:\n",
        "\n",
        "\n",
        "```yaml\n",
        "Program:\n",
        "    ClassDecl: ID(name=Example1) @ 1:1\n",
        "        VarDecl: ID(name=b) @ 3:8\n",
        "            Type: int[] @ 3:1\n",
        "            NewArray: @ 3:12\n",
        "                Type: int[]\n",
        "                Constant: int, 10 @ 3:20\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "hH6MzLo77B3f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wow. It works.\n",
        "\n",
        "Let's discuss some bits of the code."
      ],
      "metadata": {
        "id": "hGmoXULEi72n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other Considerations"
      ],
      "metadata": {
        "id": "07RcnS3kaXDi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're almost done here. There are just a few more considerations."
      ],
      "metadata": {
        "id": "54lzhmmqaiFG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Single Expressions in Expression Lists"
      ],
      "metadata": {
        "id": "c8EmISt2ar6y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expression lists with a single expression are handled differently.\n",
        "\n",
        "To not \"pollute\" AST, single expressions are not wrapped in a `ExprList` node.\n",
        "\n",
        "See the example below:\n",
        "\n",
        "```java\n",
        "class Main {\n",
        "    public static void main(String[] args) {\n",
        "        String mc = \"Susy\";\n",
        "        print(\"Hello\", mc, \". Welcome to MC921\");\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "And its AST:\n",
        "\n",
        "```yaml\n",
        "Program:\n",
        "    ClassDecl: ID(name=Main) @ 1:1\n",
        "        MainMethodDecl: @ 2:5\n",
        "            ID: args @ 2:38\n",
        "            Compound: @ 2:44\n",
        "                VarDecl: ID(name=mc) @ 3:16\n",
        "                    Type: String @ 3:9\n",
        "                    Constant: String, \"Susy\" @ 3:21\n",
        "                Print: @ 4:9\n",
        "                    ExprList: @ 4:15\n",
        "                        Constant: String, \"Hello\" @ 4:15\n",
        "                        ID: mc @ 4:24\n",
        "                        Constant: String, \". Welcome to MC921\" @ 4:28\n",
        "```\n",
        "\n",
        "\n",
        "To do this, we just write the code in the parser's `expression` production:\n",
        "\n",
        "```python\n",
        "@_(\"expression COMMA assignment_expression\")\n",
        "def expression(self, p):\n",
        "    expr_list = p.expression\n",
        "    if not isinstance(expr_list, ExprList):\n",
        "        expr_list = ExprList(exprs=[p.expression], coord=p.expression.coord)\n",
        "    expr_list.exprs.append(p.assignment_expression)\n",
        "    return expr_list\n",
        "```"
      ],
      "metadata": {
        "id": "TQ0HoBq1cjY3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The If-Else Shift/Reduce Conflict"
      ],
      "metadata": {
        "id": "KG0_zbMKd4aS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even after perfectly setting up the semantic and predence rules in you parser. You might be left with a single shift/reduce conflict.\n",
        "\n",
        "> WARNING: 1 shift/reduce conflicts\n",
        "\n",
        "This is probably the If-Else conflict:\n",
        "\n",
        "```\n",
        "if_statement -> IF ( expression ) statement .\n",
        "if_statement -> IF ( expression ) statement . ELSE statement\n",
        "```\n",
        "\n",
        "1. Shift the `ELSE` look ahead token into the stack.\n",
        "1. Reduce using rule `if_statement -> IF ( expression ) statement`.\n",
        "\n",
        "Notice that the right choice here is to shift the `ELSE` token.\n",
        "\n",
        "Since the SLY's default resolution is to shift, you don't need to solve this conflict.\n",
        "\n",
        "Oh... What's that? *You reeeeeeally want to solve this conflict?*\n",
        "\n",
        "LoL. Don't look at me. That's your problem.\n",
        "\n",
        "We don't recommend doing this for two reasons:\n",
        "\n",
        "- Rewriting semantic rules to be unambiguous [can lead to a slower and overcomplex grammar](https://www.cs.man.ac.uk/~pjj/cs212/ho/node7.html).\n",
        "- SLY's precedence can easily solve this, but it is also a bit confusing:\n",
        "\n",
        "  ```python\n",
        "  class Parser:\n",
        "      precedence = (\n",
        "          ('left', 'ELSE'),\n",
        "          ('left', ')'),\n",
        "          # [...]\n",
        "      )\n",
        "  # Is it clear why this resolves the conflict?\n",
        "  # Is it clear why it won't affect other shift/reduce conflicts?\n",
        "  ```\n",
        "\n",
        "If you're curious, look up the [\"dangling else problem\"](https://www.sanfoundry.com/c-question-dangling-else-statements/)"
      ],
      "metadata": {
        "id": "bpvpea8phNQI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Why does my Parser have 373 Shift/Reduce Conflicts?"
      ],
      "metadata": {
        "id": "W1Zrnd4Hq7lU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Is your parser overflowing with shift/reduce conflicts?\n",
        "\n",
        "Then you probably made one of the following mistakes:\n",
        "\n",
        "- Misstyped one or more semantic rules.\n",
        "- Missconfigured the `precendence` variable.\n",
        "\n",
        "Carefully review every production by the letter and look up the C language operator's precedence."
      ],
      "metadata": {
        "id": "droOVsRCq_jE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### I Have a Reduce/Reduce Conflict"
      ],
      "metadata": {
        "id": "lzFEbyJasw-v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oh boy. You've done it now. The parser is **pissed** and ready to pick a fight with you.\n",
        "\n",
        "There are too many semantic rules! It would take forever to review them all!\n",
        "\n",
        "Your knees are weak, your palms, sweaty. You take a deep breath and:\n",
        "\n",
        "<details>\n",
        "  <summary>Run</summary>\n",
        "\n",
        "* You beg for forgiveness and thoroughly review every semantic rule and EBNF to BNF conversion, searching for any typos that might have displeased the great parser.\n",
        "\n",
        "</details>\n",
        "\n",
        "\n",
        "<details>\n",
        "  <summary>Fight</summary>\n",
        "\n",
        "* Ain't no parser gonna scare you. You prepare a cup of coffe, open PLY's documentation on debugging conflicts, and gets ready to brawl.\n",
        "\n",
        "</details>\n",
        "\n",
        "<sub><sup>Just review your grammar rules. It is usually easier.</sup></sub>\n",
        "\n"
      ],
      "metadata": {
        "id": "z7A3cxpMs1KJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wrapping it Up"
      ],
      "metadata": {
        "id": "vDlb_6-ms14i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We saw a whole deal about parsers and ASTs here. And now, you're finally ready.\n",
        "\n",
        "It's time for the real deal. Clone the project's template on you machine and start coding.\n",
        "\n",
        "A few advices:\n",
        "\n",
        "- Start by adding every grammar rule in the MiniJava grammar into the parser. No need to build the AST yet. Once SLY can succesfully build the parser, then start instantiating the AST.\n",
        "- The unit tests are sorted by difficulty. When building the AST, do it test by test: instantiate only the nodes necessary for the first test to pass, then the second, and so on.\n",
        "\n",
        "Good luck!"
      ],
      "metadata": {
        "id": "Ny0_-fT92SCO"
      }
    }
  ]
}